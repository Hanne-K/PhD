---
title: "Biological lake data"
author: "Hanne B Krogstie"
date: "23.11.2022"
output: html_notebook
---
################################

## About this script

################################

In this script, I want to download, filter and organize available biological data from lakes in Fennoscandia. The goal is to start getting an overview over available material, thereby making it easier to continue planning the different projects of my PhD, including geographical scope, study design and analysis methods.

################################

## Loading required packages

################################
```{r load packages}
# Data management
library(here) # creating code with relative paths (all within the project folder)
library(rio) # convenience package for data import into R
library(tidyverse) # collection of packages that are loaded automatically: ggplot2, dplyr, tidyr,readr,purrr,tibble,stringr,forcats
library(knitr)
library(readxl) # read and write excel files
library(writexl)

# Graphics
library(sciplot) # bargraphs and lineplots
library(RColorBrewer) # color palettes, especially for nice looking maps

# Spatial files
library(sf) # spatial package
library(mapview) # interactive maps
library(geojsonsf) # converting between geojson and sf
library(rgdal) # for readOGR etc

```

################################

## Source files and import data

################################
```{r import data}
#source("example.R") # for instance, run a setup file

load(file =  here::here("Data","DerivedData","example.rda"))

```

################################

## What data do I want?

################################

Eventually, I would like to look at data collected with several sampling methods, including kick-sampling, grabb-samples and possibly surber samples.

Will choose all data that is collected with either kick-or a surber sample.

Different data sources:

* GBIF: https://www.gbif.org/
* NTNU University Museum, natron: https://natron.vm.ntnu.no/dataCollection/Login.aspx
* Swedish data portal: https://miljodata.slu.se/MVM/Search
* Finnish data portal: https://laji.fi/en 

Norway: Data is easily accessible through GBIF.

Sweden: 

Finland: Data found in the Finnish database can also be found in GBIF, but the metadata is not as good. A problem is a lack of specified sampling method. Makes it more difficult to find whole sampling events which I need if I am to look at communities.

Options:

* I could take a look at the Norwegian dataset first, which can easily be matched against lakes using NVE hydropower polygons (magasins, watercourses, rivers etc).
* I could choose a selection of taxa to include in a GBIF search, and then try to piece together sampling events via an eventID key. Thic would allow me to get an overview of the total Fennoscandian dataset. Challenge will then be to filter away data which does not belong to lakes (natural and reservoirs). Suggestion is to use the taxa included in the museum benthic invertebrate database as a template.


##################################

## 1 ) Norwegian inevrtebrate data

##################################

Using all logical phrases for sampling protocol (Rot, Kick), I see that the NTNU Museum dataset "Freshwater benthic invertebrates ecological collection NTNU University Museum" contains the majority of available occurrences (151388). The second-most useful is far less. I therefore think using sampling protocol as a search term is not very useful.

The Museum dataset: https://gbif.vm.ntnu.no/ipt/resource?r=benthic_invertebrates_biogeographical_mapping_ntnu_university_museum&v=1.570

Taxa included in this dataset: Annelida, Coleoptera, Diptera, Ephemeroptera, Hemiptera, Neuroptera, Odonata, Plecoptera, Trichoptera, Acari, Crustacea, Mollusca and represents more than 450 species.

```{r University Museum invertebrate data}

## Data from Marc

# Should use box and an api, but for now box is not working. Get NTNU box? Or find document on how to do it for free.
# library(geojsonio)
# df_bunndyr <- geojsonio::geojson_read(x =  here::here("Data","source_data","Bunndyr.geojson"))

invMuseum_sf <- geojsonsf::geojson_sf(here::here("Data","source_data","Bunndyr.geojson"))

```

```{r}
## Data from GBIF: The museum dataset for Norway
# GBIF.org (24 November 2022) GBIF Occurrence Download  https://doi.org/10.15468/dl.ee5z42
download_url <- "https://api.gbif.org/v1/occurrence/download/request/0176466-220831081235567.zip"
tmpfile <- tempfile()
tmpdir <- tempdir()
download.file(download_url,tmpfile)
occurrences <- rio::import(unzip(tmpfile,files="occurrence.txt",exdir = tmpdir), encoding = "UTF-8") # on the fly unzip and import to R object 

## Create a dataframe where each row is one location (based upon lat/long), summarized data
locations <- occurrences %>% 
  dplyr::group_by(locality, decimalLatitude,decimalLongitude) %>%
  dplyr::summarize(
    N_samplingEvents = length(unique(eventID)),
    N_taxa = length(unique(scientificName)), # could change to taxonKey?
    N_methods = length(unique(samplingProtocol)),
    methods = paste0(unique(samplingProtocol), collapse = ", "),
    N_yrs = length(unique(year)),
    years = paste0(unique(year), collapse = ", "),
    first_year = min(year),
    last_year = max(year),
    period_yrs = (last_year - first_year),
    N_months = length(unique(month)),
    months = paste0(unique(month), collapse = ", "),
    locationIDs = paste(unique(locationID), collapse=", "),
    field_number = paste0(unique(fieldNumber), collapse = ", ")) 

## Make location data-frame a spatial object 
loc_sf <- st_as_sf(locations, coords = c("decimalLongitude","decimalLatitude"), 
                   crs = 4326, remove = FALSE)

```

NVE data 
```{r}
## Data from NVE: Magasin
# UTM sone 33 (reccommended for the whole of Norway), gdb file, lndsdekkende overlapp, magasiner. WGS84 (UTM). Må bruke lengde, og breddegrader...
magasin_sf <- geojsonsf::geojson_sf(here::here("data","source_data","NVE_magasin","NVEData","Vannkraft_Magasin.geojson"))


# Data from NVE: 


```

Visualizing data
```{r}

mapview::mapView(invMuseum_sf)

mapview(loc_sf) + mapview(magasin_sf)


```

Suggestion: I can use a spatial tool to keep all points which are near lakes, either magasines or natural ones. Then from this subset I can divide it into those in magasines and those in natural lakes. I have to think about which data can be used for natural lakes. Some might have other imapct factors which make them unsuitable. Also, need to double check that the magasin file is all for hydropower. Also need to decide what kind of waterbody can be counted as a magasine? Only large natural lakes?


## Regulated lakes with data from INH

* Jonsvatnet
* Fjergen
* Innsvatnet
* Veravatnet
* Lustadvatnet
* Snåsavatnet
* Bangsjøen
* Limingen
* Øvre Kalvvatnet
* Øvre Ringvatnet
* Kalvatnet
* Unkervatn
* Elsvatn
* Krutvatnet
* Langvatn
* Isvatnet
* Storglomvatn
etc

## Regulated lakes with data from other sources

Some initial research as I look through the map.

* Røssvatnet: NINA (Fiskebiologisk etterundersøkelse i Røsvatn 1997)



## Downloading invertebrate data from other sources through GBIF.

I will add all orders that are present in the INH dataset. It may give me data from samples that havent included the entire community, but I will then go in afterwards and sort by event ID for instance. Do not know what Acari is, so I omit it for now.

Have put in the selected taxa, and find these possibly relevatn datasets: 

* Norwegian Biodiversity Information Centre - Other datasets (these are not citizen science data, but from other sources like Envir. Agency)
* Entomology, Oslo (O) UiO
* NINA insect database
* Biofokus
* Entomological collections, UiB


Your download is available at the following address:
https://api.gbif.org/v1/occurrence/download/request/0176632-220831081235567.zip

Citation: GBIF.org (24 November 2022) GBIF Occurrence Download https://doi.org/10.15468/dl.ww44ax

```{r}

download_url <- "https://api.gbif.org/v1/occurrence/download/request/0176632-220831081235567.zip"
tmpfile <- tempfile()
tmpdir <- tempdir()
download.file(download_url,tmpfile)
occurrences_multiple_datasets <- rio::import(unzip(tmpfile,files="occurrence.txt",exdir = tmpdir), encoding = "UTF-8") # on the fly unzip and import to R object 

## Create a dataframe where each row is one location (based upon lat/long), summarized data
locations_multiDat <- occurrences_multiple_datasets %>% 
  dplyr::group_by(locality, decimalLatitude,decimalLongitude) %>%
  dplyr::summarize(
    N_samplingEvents = length(unique(eventID)),
    N_taxa = length(unique(scientificName)), # could change to taxonKey?
    N_methods = length(unique(samplingProtocol)),
    methods = paste0(unique(samplingProtocol), collapse = ", "),
    N_yrs = length(unique(year)),
    years = paste0(unique(year), collapse = ", "),
    first_year = min(year),
    last_year = max(year),
    period_yrs = (last_year - first_year),
    N_months = length(unique(month)),
    months = paste0(unique(month), collapse = ", "),
    locationIDs = paste(unique(locationID), collapse=", "),
    field_number = paste0(unique(fieldNumber), collapse = ", ")) 

## Make location data-frame a spatial object 
loc_multiDat_sf <- st_as_sf(locations_multiDat, coords = c("decimalLongitude","decimalLatitude"), 
                   crs = 4326, remove = FALSE, na.fail = FALSE)


mapview(loc_multiDat_sf)
```





################################

## 2) Fennoscandian data 

################################

```{r}
mapview::mapView()


```

